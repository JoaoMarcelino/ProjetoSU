{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import *\n",
    "from shapely.ops import nearest_points\n",
    "from utils import *\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN,AgglomerativeClustering,KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsEuc,crsDeg=getUsualCRS()\n",
    "bboxEuc,bboxDeg=getUsualBbox()\n",
    "\n",
    "waterFileDir=\"../../Dados/BaseLayer/water.shp\"\n",
    "roadsFileDir=\"../../Dados/BaseLayer/roads.shp\"\n",
    "poisFileDir=\"../datasets/facebookPOIS/facebookplaces.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCentroid(cluster): \n",
    "    centroid = [MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y]\n",
    "    return centroid\n",
    "\n",
    "def dbscan(points,epsilonKm,minSamples,crs):\n",
    "    if len(points)==0:\n",
    "        raise ValueError('Empty GeoDataframe')\n",
    "        \n",
    "    coords = np.array([[p.x,p.y] for p in points.loc[:,('geometry')]])\n",
    "    \n",
    "    #dbscan  \n",
    "    db = DBSCAN(eps=epsilonKm, min_samples=minSamples).fit(coords)\n",
    "    \n",
    "    labeledPoints =db.labels_\n",
    "    uniqueClusterLabels = set(labeledPoints)\n",
    "\n",
    "    dicti = {'geometry':[],'clusterID':[],'nPoints':[]}\n",
    "    for label in uniqueClusterLabels:\n",
    "        if label==-1: #outliers are marked with clusterID=-1\n",
    "            continue\n",
    "        else:\n",
    "            cds=coords[labeledPoints==label]\n",
    "            centroid=getCentroid(cds)\n",
    "            dicti['geometry']=dicti.get('geometry',[])+[Point(centroid[0],centroid[1])]\n",
    "            dicti['clusterID']=dicti.get('clusterID',[])+[label]\n",
    "            dicti['nPoints']=dicti.get('nPoints',[])+[len(cds)]\n",
    "\n",
    "    clusters=gpd.GeoDataFrame(data=dicti,crs=crs)\n",
    "\n",
    "    points['clusterID']=labeledPoints.tolist()\n",
    "    clustersDf=reorderDataframeIndex(clusters)\n",
    "    return points,clusters\n",
    "\n",
    "def agnes(points,nClusters,crs):\n",
    "    if len(points)==0:\n",
    "        raise ValueError('Empty GeoDataframe')\n",
    "    \n",
    "    coords = np.array([[p.x,p.y] for p in points.loc[:,('geometry')]])\n",
    "\n",
    "    #aglomerative clustering \n",
    "    db = AgglomerativeClustering(n_clusters=nClusters).fit(coords)\n",
    "\n",
    "    labeledPoints =db.labels_\n",
    "    uniqueClusterLabels = set(labeledPoints)\n",
    "\n",
    "    dicti = {'geometry':[],'clusterID':[],'nPoints':[]}\n",
    "    for label in uniqueClusterLabels:\n",
    "        if label==-1: #outliers are marked with clusterID=-1\n",
    "            continue\n",
    "        else:\n",
    "            cds=coords[labeledPoints==label]\n",
    "            centroid=getCentroid(cds)\n",
    "\n",
    "            dicti['geometry']=dicti.get('geometry',[])+[Point(centroid[0],centroid[1])]\n",
    "            dicti['clusterID']=dicti.get('clusterID',[])+[label]\n",
    "            dicti['nPoints']=dicti.get('nPoints',[])+[len(cds)]\n",
    "    \n",
    "    clusters=gpd.GeoDataFrame(data=dicti,crs=crs)\n",
    "    points['clusterID']=labeledPoints.tolist()\n",
    "    clusters=reorderDataframeIndex(clusters)\n",
    "    return points,clusters\n",
    "\n",
    "def kmeans(points,nClusters,crs):\n",
    "    if len(points)==0:\n",
    "        raise ValueError('Empty GeoDataframe')\n",
    "    \n",
    "    coords = np.array([[p.x,p.y] for p in points.loc[:,('geometry')]])\n",
    "\n",
    "    #aglomerative clustering \n",
    "    db = KMeans(n_clusters=nClusters).fit(coords)\n",
    "\n",
    "    labeledPoints =db.labels_\n",
    "    uniqueClusterLabels = set(labeledPoints)\n",
    "\n",
    "    dicti = {'geometry':[],'clusterID':[],'nPoints':[]}\n",
    "    for label in uniqueClusterLabels:\n",
    "        if label==-1: #outliers are marked with clusterID=-1\n",
    "            continue\n",
    "        else:\n",
    "            cds=coords[labeledPoints==label]\n",
    "            centroid=getCentroid(cds)\n",
    "            dicti['geometry']=dicti.get('geometry',[])+[Point(centroid[0],centroid[1])]\n",
    "            dicti['clusterID']=dicti.get('clusterID',[])+[label]\n",
    "            dicti['nPoints']=dicti.get('nPoints',[])+[len(cds)]\n",
    "            \n",
    "    clusters=gpd.GeoDataFrame(data=dicti,crs=crs)\n",
    "    points['clusterID']=labeledPoints.tolist()\n",
    "    clusters=reorderDataframeIndex(clusters)\n",
    "    return points,clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSamples=3\n",
    "for i,epsilon in enumerate([300,500,700,900]):\n",
    "    ficheiroComercio=\"../datasets/facebookPOIS/Comercio.shp\"\n",
    "    poisComercio=readGeodatafromFile(targetFile=ficheiroComercio,bbox=bboxEuc,crs=crsEuc)\n",
    "\n",
    "    ficheiroComercioPois=\"../datasets/facebookPOIS/dbscan/points_{}_{}.shp\".format(minSamples,epsilon)\n",
    "    ficheiroComercioClusters=\"../datasets/facebookPOIS/dbscan/clusters_{}_{}.shp\".format(minSamples,epsilon)\n",
    "    poisComercio,clusters=dbscan(points=poisComercio,epsilonKm=epsilon,minSamples=minSamples,crs=crsEuc)\n",
    "\n",
    "    writeGeodataToGis(geodf=poisComercio,targetFile=ficheiroComercioPois,crs=crsEuc)\n",
    "    writeGeodataToGis(geodf=clusters,targetFile=ficheiroComercioClusters,crs=crsEuc)\n",
    "\n",
    "\n",
    "for i,nClusters in enumerate([5,10,20]):\n",
    "    ficheiroComercio=\"../datasets/facebookPOIS/Comercio.shp\"\n",
    "    poisComercio=readGeodatafromFile(targetFile=ficheiroComercio,bbox=bboxEuc,crs=crsEuc)\n",
    "\n",
    "    ficheiroComercioPois=\"../datasets/facebookPOIS/agnes/points_{}.shp\".format(nClusters)\n",
    "    ficheiroComercioClusters=\"../datasets/facebookPOIS/agnes/clusters_{}.shp\".format(nClusters)\n",
    "    poisComercio,clusters=agnes(nClusters=nClusters,points=poisComercio,crs=crsEuc)\n",
    "\n",
    "    writeGeodataToGis(geodf=poisComercio,targetFile=ficheiroComercioPois,crs=crsEuc)\n",
    "    writeGeodataToGis(geodf=clusters,targetFile=ficheiroComercioClusters,crs=crsEuc)\n",
    "\n",
    "\n",
    "for i,nClusters in enumerate([10]):\n",
    "    ficheiroComercio=\"../datasets/facebookPOIS/Comercio.shp\"\n",
    "    poisComercio=readGeodatafromFile(targetFile=ficheiroComercio,bbox=bboxEuc,crs=crsEuc)\n",
    "\n",
    "    ficheiroComercioPois=\"../datasets/facebookPOIS/kmeans/points_{}.shp\".format(nClusters)\n",
    "    ficheiroComercioClusters=\"../datasets/facebookPOIS/kmeans/clusters_{}.shp\".format(nClusters)\n",
    "    poisComercio,clusters=kmeans(nClusters=nClusters,points=poisComercio,crs=crsEuc)\n",
    "\n",
    "    writeGeodataToGis(geodf=poisComercio,targetFile=ficheiroComercioPois,crs=crsEuc)\n",
    "    writeGeodataToGis(geodf=clusters,targetFile=ficheiroComercioClusters,crs=crsEuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=list(taxonomy().keys())\n",
    "epsilonKm=700\n",
    "minSamples=3\n",
    "for cat in categories:\n",
    "    pointsFileDir=\"../datasets/facebookPOIS/{}.shp\".format(cat)\n",
    "    newPointsFileDir=\"../datasets/facebookPOIS/finalClustering/{}.shp\".format(cat)\n",
    "    clustersFileDir=\"../datasets/facebookPOIS/finalClustering/clusters{}.shp\".format(cat)\n",
    "\n",
    "    points=readGeodatafromFile(targetFile=pointsFileDir,bbox=bboxEuc,crs=crsEuc)\n",
    "    newPoints,clusters=dbscan(points=points,crs=crsEuc,epsilonKm=epsilonKm,minSamples=minSamples)\n",
    "\n",
    "    writeGeodataToGis(geodf=newPoints,crs=crsEuc,targetFile=newPointsFileDir)\n",
    "    writeGeodataToGis(geodf=clusters,crs=crsEuc,targetFile=clustersFileDir)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d237138e72723644b6c594b7519d0ceec22aca869e06d113d82e665c5e7816d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
